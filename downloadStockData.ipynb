{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this file is a folder with csv data files for each stock. The list of stocks comes from an external file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management\n",
    "import pandas as pd\n",
    "\n",
    "# For managing files\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "\n",
    "# For webscrapping yahoo finance\n",
    "import yfinance as yf # need to read what this does and how\n",
    "# https://github.com/ranaroussi/yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "PATH = \"D:\\\\webScrapping\\\\derekBanasTutorial\\\\\" # change accordingly\n",
    "# Folder to download stocks, create one if it doesn't exist\n",
    "folder = PATH + \"wilshire_stocks\\\\\"\n",
    "if not os.path.exists(folder): # may return false if permission is not granted\n",
    "    os.mkdir(folder)\n",
    "\n",
    "period = '2y' # Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max \n",
    "interval = '1d' # Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_from_csv(file, col_name):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : string -> path to file\n",
    "    col_name : string -> column name\n",
    "\n",
    "    Returns dataframe of column from csv file\n",
    "    '''\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found\")\n",
    "    else:\n",
    "        return df[col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tickers from an external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  3481 tickers.\n"
     ]
    }
   ],
   "source": [
    "# These will be saved as a list of strings\n",
    "tickers = get_column_from_csv(PATH + 'Wilshire-5000-Stocks.csv', 'Ticker')\n",
    "# Wilshire: index of all equities that are actively traded in the United States\n",
    "ntickers = len(tickers)\n",
    "print('There are: ',  ntickers, 'tickers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to download those tickers data from Yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some stocks may be delisted\n",
    "stocks_not_downloaded = []\n",
    "\n",
    "def save_to_csv_from_yahoo(folder, ticker, period, interval):\n",
    "    '''\n",
    "    folder: string -> path where to save file\n",
    "    ticker: string\n",
    "    period: string -> Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max \n",
    "    interval: string - > Valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "    Intraday data cannot extend last 60 days\n",
    "\n",
    "    Downloads stock data from yahoo finance and saves it in a ticker.csv file in folder\n",
    "    '''\n",
    "    stock = yf.Ticker(ticker)\n",
    "    # yahoo finance datetimes are received as UTC.\n",
    "    \n",
    "    try:\n",
    "        print(\"Get data for: \", ticker)\n",
    "        # Get historical closing price data\n",
    "        df = stock.history(period=period, interval=interval)\n",
    "        # 5 years is enough (medium term) maybe even 2, depends what you want to do\n",
    "        \n",
    "        # Wait a prudent time\n",
    "        time.sleep(2) # in seconds\n",
    "        \n",
    "        # If there is no data from Yahoo\n",
    "        if df.empty:\n",
    "            stocks_not_downloaded.append(ticker)\n",
    "        \n",
    "        # Remove a possible period in the file name with a _\n",
    "        the_file = folder + ticker.replace(\".\", \"_\") + '.csv'\n",
    "        print(the_file, \" saved!\")\n",
    "        df.to_csv(the_file)\n",
    "    except Exception as ex:\n",
    "        stocks_not_downloaded.append(ticker)\n",
    "        # err_msg.append(ex)\n",
    "        print(\"Could not get data for \" + ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get those files in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 500\n",
    "\n",
    "# since 0 % 500 is 0, this loop begins by waiting 20 seconds\n",
    "for i in range(ntickers):\n",
    "    if i % batch != 0:\n",
    "        save_to_csv_from_yahoo(folder, tickers[i], period, interval)\n",
    "    else:\n",
    "        print(\"Finished \", i,\" !!\")\n",
    "        print(\"==============================================================\")\n",
    "        time.sleep(20)\n",
    "print(\"Finished All!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete empty files\n",
    "Some times empty files or files with not enough data (< 16 rows) are downloaded, delete those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  stocks not downloaded.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Get tickers from downloaded stock files\n",
    "files = [f for f in listdir(folder) if isfile(join(folder, f))] \n",
    "downloaded_tickers = [os.path.splitext(f)[0] for f in files] # split file extension. List of strings\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        if os.path.getsize(folder+'\\\\'+file) < 2000: # 2 kB ~ 16 rows\n",
    "            stocks_not_downloaded.append(os.path.splitext(file)[0])\n",
    "            os.remove(file)\n",
    "    except OSError as ose:\n",
    "        print(ose)\n",
    "\n",
    "print(len(stocks_not_downloaded), \" stocks not downloaded.\")\n",
    "print(stocks_not_downloaded)        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fd932d485fdce91e1fb74be4a067eb0acb26380b8938bf9d6ae576de7de3bff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('webScrapping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
